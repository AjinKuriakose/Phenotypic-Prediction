{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as cPickle\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn import cluster as Kcluster, metrics as Met ,preprocessing as preprocessing\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import metrics, cross_validation\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data, flatten and subsample the classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Sample Set . Holds the sample IDs and the labels under the column [accession,label]\n",
    "SAMPLES = pd.read_csv(r\"C:\\Users\\ajinkuriakose\\Desktop\\Computational Biology\\Project\\p1_train.csv\", sep=',', error_bad_lines=False)\n",
    "labels = ['CEU','FIN','GBR','TSI','YRI']\n",
    "sample_set = pd.DataFrame()\n",
    "\n",
    "#Equally Subsample from each of the classses\n",
    "for lab in labels:\n",
    "    SAMPLES_FILETERED = SAMPLES[SAMPLES.label == lab].sample(n=50)\n",
    "    sample_set =sample_set.append(SAMPLES_FILETERED,ignore_index=False)\n",
    "    \n",
    "# pickle.dump(sample_set,open(\"sample300_ids.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "#Create Data Set\n",
    "# sample_set= pickle.load(open(\"sample75_ids.pkl\",'rb'))\n",
    "sample_set_id = sample_set['accession']\n",
    "sample_data = pd.DataFrame()\n",
    "root = r\"C:\\Users\\ajinkuriakose\\Desktop\\Computational Biology\\train\"\n",
    "for sampleid in sample_set_id:\n",
    "    try:\n",
    "        #ambig_info_df = pd.read_csv(root+\"\\\\\"+sampleid+ '\\\\bias\\\\aux_info\\\\ambig_info.tsv',sep='\\t',error_bad_lines=False)\n",
    "        quantified_data = pd.read_csv(root+\"\\\\\"+sampleid+\"\\\\bias\\\\quant1.sf\",sep='\\t',error_bad_lines=False)\n",
    "        #quantified_data = pd.DataFrame(pd.concat([quantified_data, ambig_info_df], axis=1).set_index('Name').stack()).transpose()\n",
    "        quantified_data = pd.DataFrame(quantified_data.set_index('Name').stack()).transpose()\n",
    "        sample_data = sample_data.append(quantified_data)\n",
    "    except KeyboardInterrupt:\n",
    "        break \n",
    "#     sample_data.drop('Length', axis=1, level=1, inplace=True)\n",
    "#     pickle.dump(sample_data, open(\"data_ambig_300.pkl\", 'wb'))\n",
    "# '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally Load the data from data that was pickled previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 797296)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data= pickle.load(open(\"data_ambig_250.pkl\",'rb')) #data_150.pkl\n",
    "sample_data= sample_data.dropna() \n",
    "sample_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th colspan=\"5\" halign=\"left\">ENST00000456328.2</th>\n",
       "      <th colspan=\"5\" halign=\"left\">ENST00000450305.2</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"5\" halign=\"left\">ENST00000387460.2</th>\n",
       "      <th colspan=\"5\" halign=\"left\">ENST00000387461.2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>EffectiveLength</th>\n",
       "      <th>TPM</th>\n",
       "      <th>NumReads</th>\n",
       "      <th>UniqueCount</th>\n",
       "      <th>AmbigCount</th>\n",
       "      <th>EffectiveLength</th>\n",
       "      <th>TPM</th>\n",
       "      <th>NumReads</th>\n",
       "      <th>UniqueCount</th>\n",
       "      <th>AmbigCount</th>\n",
       "      <th>...</th>\n",
       "      <th>EffectiveLength</th>\n",
       "      <th>TPM</th>\n",
       "      <th>NumReads</th>\n",
       "      <th>UniqueCount</th>\n",
       "      <th>AmbigCount</th>\n",
       "      <th>EffectiveLength</th>\n",
       "      <th>TPM</th>\n",
       "      <th>NumReads</th>\n",
       "      <th>UniqueCount</th>\n",
       "      <th>AmbigCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1449.77</td>\n",
       "      <td>0.085384</td>\n",
       "      <td>2.14102</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>486.623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>421.238</td>\n",
       "      <td>153.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3350.63</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>1217.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1503.66</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>498.230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>384.092</td>\n",
       "      <td>138.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2148.69</td>\n",
       "      <td>772.0</td>\n",
       "      <td>772.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1501.26</td>\n",
       "      <td>0.083892</td>\n",
       "      <td>3.44368</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>169.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>119.341</td>\n",
       "      <td>62.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2333.32</td>\n",
       "      <td>1276.0</td>\n",
       "      <td>1276.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1454.66</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>184.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>331.118</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4394.02</td>\n",
       "      <td>2104.0</td>\n",
       "      <td>2104.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1408.86</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>459.052</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1323.940</td>\n",
       "      <td>674.0</td>\n",
       "      <td>674.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3628.06</td>\n",
       "      <td>1847.0</td>\n",
       "      <td>1847.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 996620 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Name ENST00000456328.2                                            \\\n",
       "       EffectiveLength       TPM NumReads UniqueCount AmbigCount   \n",
       "0              1449.77  0.085384  2.14102         1.0        6.0   \n",
       "0              1503.66  0.000000  0.00000         0.0        4.0   \n",
       "0              1501.26  0.083892  3.44368         1.0        3.0   \n",
       "0              1454.66  0.000000  0.00000         0.0        2.0   \n",
       "0              1408.86  0.000000  0.00000         0.0        5.0   \n",
       "\n",
       "Name ENST00000450305.2                                         ...      \\\n",
       "       EffectiveLength  TPM NumReads UniqueCount AmbigCount    ...       \n",
       "0              486.623  0.0      0.0         0.0        1.0    ...       \n",
       "0              498.230  0.0      0.0         0.0        1.0    ...       \n",
       "0              169.000  0.0      0.0         0.0        0.0    ...       \n",
       "0              184.000  0.0      0.0         0.0        0.0    ...       \n",
       "0              459.052  0.0      0.0         0.0        1.0    ...       \n",
       "\n",
       "Name ENST00000387460.2                                            \\\n",
       "       EffectiveLength       TPM NumReads UniqueCount AmbigCount   \n",
       "0                 21.0   421.238    153.0       153.0        0.0   \n",
       "0                 22.0   384.092    138.0       138.0        0.0   \n",
       "0                 19.0   119.341     62.0        62.0        0.0   \n",
       "0                 20.0   331.118    151.0       151.0        0.0   \n",
       "0                 22.0  1323.940    674.0       674.0        0.0   \n",
       "\n",
       "Name ENST00000387461.2                                           \n",
       "       EffectiveLength      TPM NumReads UniqueCount AmbigCount  \n",
       "0                 21.0  3350.63   1217.0      1217.0        0.0  \n",
       "0                 22.0  2148.69    772.0       772.0        0.0  \n",
       "0                 20.0  2333.32   1276.0      1276.0        0.0  \n",
       "0                 21.0  4394.02   2104.0      2104.0        0.0  \n",
       "0                 22.0  3628.06   1847.0      1847.0        0.0  \n",
       "\n",
       "[5 rows x 996620 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class predictorROC:\n",
    "    \n",
    "    #Yreal is the real outcome value, Yscore is the caluclated value\n",
    "    #threshold is the threshold value to calculate the specificity and sensitivity\n",
    "    \n",
    "    def draw_roc(self, Yreal, Yscore):\n",
    "        fpr = []\n",
    "        tpr = []\n",
    "        roc_auc = []\n",
    "        fpr, tpr, _ = roc_curve(Yreal, Yscore)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "\n",
    "        plt.figure()\n",
    "        lw = 2\n",
    "        plt.plot(fpr, tpr, color='darkorange',\n",
    "                 lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver operating characteristic example')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction Using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eigenvalues(data):\n",
    "    U, V, W = np.linalg.svd(data, full_matrices=False)\n",
    "    return U,V\n",
    "\n",
    "def perf_pca(data):\n",
    "    #U, V, W = np.linalg.svd(data, full_matrices=False)\n",
    "    #newV = [x for x in V if x >= 1]\n",
    "    # find the number of principal components.\n",
    "    # select the components with eigenvalue greater than 1.\n",
    "    #dim = len(newV)\n",
    "    sk_pca = sklearnPCA(n_components=100)\n",
    "    pca = sk_pca.fit_transform(data)\n",
    "    return pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unable to do normalization for large inputs due to memory issues.\n",
    "# Normalize the data\n",
    "sample_norm_data = preprocessing.scale(np.array(sample_data))\n",
    "# Compute the correlation matrix\n",
    "sample_corr_data = np.corrcoef(sample_norm_data, rowvar=False)\n",
    "#pca_sample = perf_pca(sample_corr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250, 250)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca=perf_pca(sample_data)\n",
    "# pca = pickle.load(open(\"pca_ambig_250.pkl\",'rb'))\n",
    "pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=75)\n",
    "rf.fit(X_train, y_train)\n",
    "predictions = rf.predict(X_test)\n",
    "\n",
    "#Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train, y_train)\n",
    "predictions = dtree.predict(X_test)\n",
    "\n",
    "#\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logm = LogisticRegression()\n",
    "logm.fit(X_train, y_train)\n",
    "predictions = logm.predict(X_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model using LogisticRegression and 5-fold cross validation and show the classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy : 0.808\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        CEU       0.92      0.90      0.91        50\n",
      "        FIN       0.77      0.72      0.74        50\n",
      "        GBR       0.74      0.80      0.77        50\n",
      "        TSI       0.68      0.80      0.73        50\n",
      "        YRI       1.00      0.82      0.90        50\n",
      "\n",
      "avg / total       0.82      0.81      0.81       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sample_set_label\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(pca, sample_set_label, test_size=0.3, random_state=101)\n",
    "# y = [['CEU','FIN','GBR','TSI','YRI'].index(i) for i in sample_set_label]\n",
    "\n",
    "sample_set_label = sample_set['label']\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "predicted = cross_validation.cross_val_predict(LogisticRegression(), pca, sample_set_label, cv=5)\n",
    "print (\"Overall Accuracy :\",metrics.accuracy_score(sample_set_label, predicted))\n",
    "print (\"\\n\")\n",
    "print (metrics.classification_report(sample_set_label, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "523env",
   "language": "python",
   "name": "523env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16.0,
    "lenType": 16.0,
    "lenVar": 40.0
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}